{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Vector ü¶úüîó\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Multi-Vector l√† m·ªôt ph∆∞∆°ng ph√°p ti√™n ti·∫øn c·ªßa giai ƒëo·∫°n Indexing (l·∫≠p ch·ªâ m·ª•c) trong retrieval (truy xu·∫•t).\n",
    "\n",
    "Th√¥ng th∆∞·ªùng, c√°c t√†i li·ªáu th√¥, ƒë∆∞·ª£c chia th√†nh chunk (ƒëo·∫°n) c·ªßa b·∫°n c√≥ th·ªÉ *kh√¥ng* ph·∫£i l√† vƒÉn b·∫£n t·ªëi ∆∞u ƒë·ªÉ l·∫•y embeddings (nh√∫ng). \n",
    "\n",
    "C√≥ th·ªÉ x·∫£y ra tr∆∞·ªùng h·ª£p m·ªôt vƒÉn b·∫£n thay th·∫ø ƒë∆∞·ª£c suy ra t·ª´ c√°c t√†i li·ªáu g·ªëc c·ªßa b·∫°n s·∫Ω t·ªët h∆°n. ƒêi·ªÅu n√†y c√≥ th·ªÉ bao g·ªìm summaries (t√≥m t·∫Øt), hypothetical questions (c√¢u h·ªèi gi·∫£ ƒë·ªãnh), extractions (tr√≠ch xu·∫•t) ho·∫∑c child documents (t√†i li·ªáu con).\n",
    "\n",
    "M·ª•c ti√™u c·ªßa multi-vector retrieval (truy xu·∫•t ƒëa vector) l√† c√≥ th√™m embeddings (nh√∫ng) trong qu√° tr√¨nh retrieval (truy xu·∫•t) c·ªßa b·∫°n, c√≥ th·ªÉ ph√π h·ª£p h∆°n v·ªõi c√°c queries (truy v·∫•n) d·ª± ki·∫øn c·ªßa b·∫°n.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://retrieval-tutorials.vercel.app/assets/images/MultiVector-a662f0115469e34ca0fc32eec9f9d9ca.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is this helpful?‚Äã\n",
    "\n",
    "ƒêi·ªÅu n√†y h·ªØu √≠ch khi c√≥ m·ªôt d·∫°ng ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω ho·∫∑c suy ra t·ª´ c√°c t√†i li·ªáu g·ªëc c·ªßa b·∫°n ph√π h·ª£p h∆°n v·ªõi qu√° tr√¨nh search (t√¨m ki·∫øm) c·ªßa b·∫°n. H√£y coi ƒë√¢y nh∆∞ m·ªôt b∆∞·ªõc pre-processing (ti·ªÅn x·ª≠ l√Ω) tr√™n c√°c t√†i li·ªáu c·ªßa b·∫°n, nh·∫±m m·ª•c ƒë√≠ch ph√π h·ª£p h∆°n v·ªõi nhu c·∫ßu search (t√¨m ki·∫øm) c·ªßa b·∫°n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import  FAISS\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model='bge-m3:latest')\n",
    "chapter_summaries_vectorstore =  FAISS.load_local(\"data/chapter_summaries_vector_store\", embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "id_key = \"doc_id\" # This is the key that we will tell the retriever to connect the summaries and original docs on\n",
    "\n",
    "docstore = InMemoryStore()\n",
    "\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=chapter_summaries_vectorstore,\n",
    "    docstore=docstore,\n",
    "    id_key=id_key, # \"Hey, what should we join on?\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
