{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Conversational Agent with Context Awareness\n",
    "\n",
    "Xây dựng Agent đàm thoại có nhận thức ngữ cảnh\n",
    "\n",
    "## Tổng quan\n",
    "Hướng dẫn này phác thảo quy trình tạo ra một agent đàm thoại có thể duy trì ngữ cảnh qua nhiều tương tác. Chúng ta sẽ sử dụng một framework AI hiện đại để xây dựng một agent có khả năng tham gia vào các cuộc trò chuyện tự nhiên và mạch lạc hơn.\n",
    "\n",
    "## Động lực\n",
    "Nhiều chatbot đơn giản thiếu khả năng duy trì ngữ cảnh, dẫn đến trải nghiệm người dùng rời rạc và khó chịu. Hướng dẫn này nhằm mục đích giải quyết vấn đề đó bằng cách triển khai một agent đàm thoại có thể ghi nhớ và tham khảo các phần trước của cuộc trò chuyện, nâng cao chất lượng tương tác tổng thể.\n",
    "\n",
    "## Các thành phần chính\n",
    "1.  **Language Model (Mô hình ngôn ngữ)**: Thành phần AI cốt lõi tạo ra các phản hồi.\n",
    "2.  **Prompt Template (Mẫu Prompt)**: Định nghĩa cấu trúc của các cuộc trò chuyện của chúng ta.\n",
    "3.  **History Manager (Trình quản lý lịch sử)**: Quản lý lịch sử và ngữ cảnh cuộc trò chuyện.\n",
    "4.  **Message Store (Kho lưu trữ tin nhắn)**: Lưu trữ các tin nhắn cho mỗi phiên trò chuyện.\n",
    "\n",
    "## Chi tiết phương pháp\n",
    "\n",
    "### Thiết lập môi trường\n",
    "Bắt đầu bằng cách thiết lập framework AI cần thiết và đảm bảo quyền truy cập vào một language model phù hợp. Điều này tạo thành nền tảng của agent đàm thoại của chúng ta.\n",
    "\n",
    "### Tạo kho lưu trữ lịch sử trò chuyện\n",
    "Triển khai một hệ thống để quản lý nhiều phiên trò chuyện. Mỗi phiên phải được xác định duy nhất và liên kết với lịch sử tin nhắn riêng của nó.\n",
    "\n",
    "### Định nghĩa cấu trúc cuộc trò chuyện\n",
    "Tạo một template bao gồm:\n",
    "-   Một system message (tin nhắn hệ thống) định nghĩa vai trò của AI.\n",
    "-   Một placeholder (vị trí giữ chỗ) cho lịch sử cuộc trò chuyện.\n",
    "-   Đầu vào của người dùng.\n",
    "\n",
    "Cấu trúc này hướng dẫn các phản hồi của AI và duy trì tính nhất quán trong suốt cuộc trò chuyện.\n",
    "\n",
    "### Xây dựng chuỗi đàm thoại\n",
    "Kết hợp prompt template với language model để tạo một chuỗi đàm thoại cơ bản. Bọc chuỗi này bằng một component quản lý lịch sử, tự động xử lý việc chèn và truy xuất lịch sử cuộc trò chuyện.\n",
    "\n",
    "### Tương tác với Agent\n",
    "Để sử dụng agent, hãy gọi nó với đầu vào của người dùng và một session identifier (định danh phiên). History manager đảm nhận việc truy xuất lịch sử cuộc trò chuyện thích hợp, chèn nó vào prompt và lưu trữ các tin nhắn mới sau mỗi tương tác.\n",
    "\n",
    "## Kết luận\n",
    "Phương pháp tạo agent đàm thoại này mang lại một số lợi thế:\n",
    "-   **Context Awareness (Nhận thức ngữ cảnh)**: Agent có thể tham khảo các phần trước của cuộc trò chuyện, dẫn đến các tương tác tự nhiên hơn.\n",
    "-   **Simplicity (Sự đơn giản)**: Thiết kế mô-đun giữ cho việc triển khai đơn giản.\n",
    "-   **Flexibility (Tính linh hoạt)**: Dễ dàng sửa đổi cấu trúc cuộc trò chuyện hoặc chuyển sang một language model khác.\n",
    "-   **Scalability (Khả năng mở rộng)**: Phương pháp dựa trên phiên cho phép quản lý nhiều cuộc trò chuyện độc lập.\n",
    "\n",
    "Với nền tảng này, bạn có thể nâng cao hơn nữa agent bằng cách:\n",
    "-   Triển khai prompt engineering (kỹ thuật prompt) phức tạp hơn.\n",
    "-   Tích hợp nó với các knowledge base (cơ sở tri thức) bên ngoài.\n",
    "-   Thêm các khả năng chuyên biệt cho các domain (lĩnh vực) cụ thể.\n",
    "-   Kết hợp xử lý lỗi và các chiến lược sửa chữa cuộc trò chuyện.\n",
    "\n",
    "Bằng cách tập trung vào quản lý ngữ cảnh, thiết kế agent đàm thoại này cải thiện đáng kể chức năng chatbot cơ bản, mở đường cho các trợ lý AI hấp dẫn và hữu ích hơn.\n",
    "\n",
    "- Requirements\n",
    "\n",
    "```bash\n",
    "pip install -q langchain langchain_experimental openai python-dotenv langchain_ollama\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOllama(model='qwen2.5:7b', temperature=0, num_predict=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create a simple in-memory store for chat histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "def get_chat_history(session_id: str):\n",
    "  if session_id not in store:\n",
    "    store[session_id] = ChatMessageHistory()\n",
    "  return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"You are a helpful AI assistant\"),\n",
    "  MessagesPlaceholder(variable_name=\"history\"),\n",
    "  (\"human\", \"{input}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the prompt and the model into a runable chain\n",
    "chain = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the chain with message history\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "  chain,\n",
    "  get_chat_history,\n",
    "  input_messages_key=\"input\",\n",
    "  history_messages_key='history'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:  Rất vui được gặp bạn, Dino! Bạn có cần giúp đỡ gì hôm nay không? Tôi có thể hỗ trợ bạn với nhiều chủ đề khác nhau như tìm thông tin, giải đáp thắc mắc hoặc chỉ đơn giản là trò chuyện.\n"
     ]
    }
   ],
   "source": [
    "session_id=\"userA\"\n",
    "\n",
    "response = chain_with_history.invoke(\n",
    "  {\"input\": \"Tên tôi là Dino\"},\n",
    "  config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(\"AI: \", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:  Bạn tên là Dino.\n"
     ]
    }
   ],
   "source": [
    "response2 = chain_with_history.invoke(\n",
    "  {\"input\": \"Tôi tên là gì?\"},\n",
    "  config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(\"AI: \", response2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Tên tôi là Dino', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Rất vui được gặp bạn, Dino! Bạn có cần giúp đỡ gì hôm nay không? Tôi có thể hỗ trợ bạn với nhiều chủ đề khác nhau như tìm thông tin, giải đáp thắc mắc hoặc chỉ đơn giản là trò chuyện.', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-03-20T09:35:56.453670741Z', 'done': True, 'done_reason': 'stop', 'total_duration': 11817039901, 'load_duration': 2753618353, 'prompt_eval_count': 24, 'prompt_eval_duration': 1663000000, 'eval_count': 54, 'eval_duration': 7394000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-37bd517c-ae56-48f3-8abd-d6413230ef20-0', usage_metadata={'input_tokens': 24, 'output_tokens': 54, 'total_tokens': 78}),\n",
       " HumanMessage(content='Tôi tên là gì?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Bạn tên là Dino.', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-03-20T09:36:29.734005265Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1775143924, 'load_duration': 17823693, 'prompt_eval_count': 92, 'prompt_eval_duration': 1072000000, 'eval_count': 7, 'eval_duration': 671000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-98a42784-7d39-4f09-b7bf-3b4d9dba9720-0', usage_metadata={'input_tokens': 92, 'output_tokens': 7, 'total_tokens': 99})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store[session_id].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human: Tên tôi là Dino\n",
      "ai: Rất vui được gặp bạn, Dino! Bạn có cần giúp đỡ gì hôm nay không? Tôi có thể hỗ trợ bạn với nhiều chủ đề khác nhau như tìm thông tin, giải đáp thắc mắc hoặc chỉ đơn giản là trò chuyện.\n",
      "human: Tôi tên là gì?\n",
      "ai: Bạn tên là Dino.\n"
     ]
    }
   ],
   "source": [
    "# Print the conversation history\n",
    "for message in store[session_id].messages:\n",
    "  print(f\"{message.type}: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
