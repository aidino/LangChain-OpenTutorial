{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reliable-RAG üè∑Ô∏è\n",
    "\n",
    "### T·ªïng quan\n",
    "\n",
    "Ph∆∞∆°ng ph√°p \"Reliable-RAG\" (Retrieval-Augmented Generation ƒë√°ng tin c·∫≠y) n√¢ng cao c√°ch ti·∫øp c·∫≠n RAG truy·ªÅn th·ªëng b·∫±ng c√°ch th√™m c√°c l·ªõp x√°c th·ª±c v√† tinh ch·ªânh ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh ch√≠nh x√°c v√† m·ª©c ƒë·ªô li√™n quan c·ªßa th√¥ng tin ƒë∆∞·ª£c truy xu·∫•t. H·ªá th·ªëng n√†y ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ x·ª≠ l√Ω v√† truy v·∫•n c√°c t√†i li·ªáu d·ª±a tr√™n web, m√£ h√≥a n·ªôi dung c·ªßa ch√∫ng v√†o m·ªôt kho vector (vector store), v√† truy xu·∫•t c√°c ph√¢n ƒëo·∫°n li√™n quan nh·∫•t ƒë·ªÉ t·∫°o ra c√°c c√¢u tr·∫£ l·ªùi ch√≠nh x√°c v√† ƒë√°ng tin c·∫≠y. Ph∆∞∆°ng ph√°p n√†y k·∫øt h·ª£p c√°c ki·ªÉm tra v·ªÅ m·ª©c ƒë·ªô li√™n quan c·ªßa t√†i li·ªáu, ngƒÉn ch·∫∑n ·∫£o gi√°c (hallucination), v√† l√†m n·ªïi b·∫≠t c√°c ph√¢n ƒëo·∫°n ch√≠nh x√°c ƒë∆∞·ª£c s·ª≠ d·ª•ng trong vi·ªác t·∫°o ra ph·∫£n h·ªìi cu·ªëi c√πng.\n",
    "\n",
    "### C√°c th√†nh ph·∫ßn ch√≠nh\n",
    "\n",
    "1.  **T·∫£i v√† ph√¢n ƒëo·∫°n t√†i li·ªáu (Document Loading and Chunking):**\n",
    "    * C√°c t√†i li·ªáu d·ª±a tr√™n web ƒë∆∞·ª£c t·∫£i v√† chia th√†nh c√°c ƒëo·∫°n nh·ªè, d·ªÖ qu·∫£n l√Ω ƒë·ªÉ t·∫°o ƒëi·ªÅu ki·ªán m√£ h√≥a v√† truy xu·∫•t vector hi·ªáu qu·∫£.\n",
    "\n",
    "2.  **T·∫°o kho vector (Vectorstore Creation):**\n",
    "    * S·ª≠ d·ª•ng Chroma v√† Cohere embeddings ƒë·ªÉ m√£ h√≥a c√°c ƒëo·∫°n t√†i li·ªáu v√†o m·ªôt kho vector, cho ph√©p truy xu·∫•t d·ª±a tr√™n ƒë·ªô t∆∞∆°ng t·ª± hi·ªáu qu·∫£.\n",
    "\n",
    "3.  **Ki·ªÉm tra m·ª©c ƒë·ªô li√™n quan c·ªßa t√†i li·ªáu (Document Relevancy Check):**\n",
    "    * Tri·ªÉn khai c∆° ch·∫ø ki·ªÉm tra m·ª©c ƒë·ªô li√™n quan b·∫±ng c√°ch s·ª≠ d·ª•ng m√¥ h√¨nh ng√¥n ng·ªØ ƒë·ªÉ l·ªçc ra c√°c t√†i li·ªáu kh√¥ng li√™n quan tr∆∞·ªõc khi t·∫°o c√¢u tr·∫£ l·ªùi.\n",
    "\n",
    "4.  **T·∫°o c√¢u tr·∫£ l·ªùi (Answer Generation):**\n",
    "    * S·ª≠ d·ª•ng m√¥ h√¨nh ng√¥n ng·ªØ ƒë·ªÉ t·∫°o ra c√°c c√¢u tr·∫£ l·ªùi ng·∫Øn g·ªçn d·ª±a tr√™n c√°c t√†i li·ªáu li√™n quan ƒë∆∞·ª£c truy xu·∫•t.\n",
    "\n",
    "5.  **Ph√°t hi·ªán ·∫£o gi√°c (Hallucination Detection):**\n",
    "    * B∆∞·ªõc ph√°t hi·ªán ·∫£o gi√°c chuy√™n d·ª•ng ƒë·∫£m b·∫£o r·∫±ng c√°c c√¢u tr·∫£ l·ªùi ƒë∆∞·ª£c t·∫°o ra d·ª±a tr√™n c√°c t√†i li·ªáu ƒë∆∞·ª£c truy xu·∫•t, ngƒÉn ch·∫∑n vi·ªác ƒë∆∞a v√†o th√¥ng tin kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£ ho·∫∑c sai s√≥t.\n",
    "\n",
    "6.  **L√†m n·ªïi b·∫≠t ƒëo·∫°n tr√≠ch t√†i li·ªáu (Document Snippet Highlighting):**\n",
    "    * H·ªá th·ªëng x√°c ƒë·ªãnh v√† l√†m n·ªïi b·∫≠t c√°c ph√¢n ƒëo·∫°n t√†i li·ªáu c·ª• th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng tr·ª±c ti·∫øp ƒë·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi, cung c·∫•p t√≠nh minh b·∫°ch v√† kh·∫£ nƒÉng truy xu·∫•t ngu·ªìn g·ªëc.\n",
    "\n",
    "### ƒê·ªông l·ª±c\n",
    "\n",
    "Ph∆∞∆°ng ph√°p Reliable-RAG ƒë∆∞·ª£c ph√°t tri·ªÉn ƒë·ªÉ gi·∫£i quy·∫øt c√°c th√°ch th·ª©c ph·ªï bi·∫øn trong c√°c h·ªá th·ªëng RAG truy·ªÅn th·ªëng, ch·∫≥ng h·∫°n nh∆∞ truy xu·∫•t c√°c t√†i li·ªáu kh√¥ng li√™n quan, t·∫°o ra c√°c c√¢u tr·∫£ l·ªùi kh√¥ng d·ª±a tr√™n s·ª± ki·ªán v√† thi·∫øu t√≠nh minh b·∫°ch trong c√°c ngu·ªìn ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi. B·∫±ng c√°ch th√™m nhi·ªÅu l·ªõp x√°c th·ª±c, ph∆∞∆°ng ph√°p n√†y ƒë·∫£m b·∫£o r·∫±ng c√°c c√¢u tr·∫£ l·ªùi ƒë∆∞·ª£c cung c·∫•p v·ª´a ch√≠nh x√°c v·ª´a ƒë√°ng tin c·∫≠y.\n",
    "\n",
    "### Chi ti·∫øt v√† l·ª£i √≠ch c·ªßa ph∆∞∆°ng ph√°p\n",
    "\n",
    "* **L·ªçc m·ª©c ƒë·ªô li√™n quan c·ªßa t√†i li·ªáu (Document Relevancy Filtering):**\n",
    "    * B·∫±ng c√°ch s·ª≠ d·ª•ng ƒëi·ªÉm s·ªë m·ª©c ƒë·ªô li√™n quan nh·ªã ph√¢n ƒë∆∞·ª£c t·∫°o b·ªüi m√¥ h√¨nh ng√¥n ng·ªØ, ch·ªâ c√°c t√†i li·ªáu li√™n quan nh·∫•t m·ªõi ƒë∆∞·ª£c chuy·ªÉn sang giai ƒëo·∫°n t·∫°o c√¢u tr·∫£ l·ªùi, gi·∫£m nhi·ªÖu v√† c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng c·ªßa c√¢u tr·∫£ l·ªùi cu·ªëi c√πng.\n",
    "\n",
    "* **Ki·ªÉm tra ·∫£o gi√°c (Hallucination Check):**\n",
    "    * Tr∆∞·ªõc khi ho√†n thi·ªán c√¢u tr·∫£ l·ªùi, h·ªá th·ªëng ki·ªÉm tra ·∫£o gi√°c b·∫±ng c√°ch x√°c minh r·∫±ng n·ªôi dung ƒë∆∞·ª£c t·∫°o ra ƒë∆∞·ª£c h·ªó tr·ª£ ƒë·∫ßy ƒë·ªß b·ªüi c√°c t√†i li·ªáu ƒë∆∞·ª£c truy xu·∫•t.\n",
    "\n",
    "* **L√†m n·ªïi b·∫≠t ƒëo·∫°n tr√≠ch (Snippet Highlighting):**\n",
    "    * T√≠nh nƒÉng n√†y tƒÉng c∆∞·ªùng t√≠nh minh b·∫°ch b·∫±ng c√°ch hi·ªÉn th·ªã c√°c ph√¢n ƒëo·∫°n ch√≠nh x√°c t·ª´ c√°c t√†i li·ªáu ƒë∆∞·ª£c truy xu·∫•t ƒë√£ ƒë√≥ng g√≥p v√†o c√¢u tr·∫£ l·ªùi cu·ªëi c√πng.\n",
    "\n",
    "## Tri·ªÉn khai\n",
    "\n",
    "### Tri·ªÉn khai Python t·ª´ng b∆∞·ªõc\n",
    "\n",
    "1.  **Nh·∫≠p th∆∞ vi·ªán v√† ƒë·∫∑t bi·∫øn m√¥i tr∆∞·ªùng (Import Libraries and Set Environment Variables)**\n",
    "    * Nh·∫≠p c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt v√† ƒë·∫∑t c√°c bi·∫øn m√¥i tr∆∞·ªùng ƒë·ªÉ truy c·∫≠p LLM v√† m√¥ h√¨nh embedding.\n",
    "\n",
    "2.  **T·∫°o kho vector (Create Vectorstore)**\n",
    "    * T·∫£i c√°c t√†i li·ªáu d·ª±a tr√™n web, chia ch√∫ng th√†nh c√°c ƒëo·∫°n v√† t·∫°o kho vector b·∫±ng c√°ch s·ª≠ d·ª•ng Chroma v√† Cohere embeddings.\n",
    "\n",
    "3.  **Truy v·∫•n c√¢u h·ªèi (Question Query)**\n",
    "    * X√°c ƒë·ªãnh truy v·∫•n c·ªßa ng∆∞·ªùi d√πng v√† truy xu·∫•t c√°c t√†i li·ªáu li√™n quan h√†ng ƒë·∫ßu t·ª´ kho vector.\n",
    "\n",
    "4.  **Ki·ªÉm tra m·ª©c ƒë·ªô li√™n quan c·ªßa t√†i li·ªáu (Check Document Relevancy)**\n",
    "    * L·ªçc ra c√°c t√†i li·ªáu kh√¥ng li√™n quan b·∫±ng c√°ch s·ª≠ d·ª•ng ƒëi·ªÉm s·ªë m·ª©c ƒë·ªô li√™n quan nh·ªã ph√¢n do m√¥ h√¨nh ng√¥n ng·ªØ cung c·∫•p.\n",
    "\n",
    "5.  **T·∫°o c√¢u tr·∫£ l·ªùi (Generate Answer)**\n",
    "    * S·ª≠ d·ª•ng c√°c t√†i li·ªáu li√™n quan ƒë·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi ng·∫Øn g·ªçn cho truy v·∫•n c·ªßa ng∆∞·ªùi d√πng.\n",
    "\n",
    "6.  **Ki·ªÉm tra ·∫£o gi√°c (Check for Hallucinations)**\n",
    "    * ƒê·∫£m b·∫£o r·∫±ng c√¢u tr·∫£ l·ªùi ƒë∆∞·ª£c t·∫°o ra d·ª±a tr√™n ƒë·∫ßy ƒë·ªß c√°c t√†i li·ªáu ƒë∆∞·ª£c truy xu·∫•t.\n",
    "\n",
    "7.  **L√†m n·ªïi b·∫≠t ƒëo·∫°n tr√≠ch t√†i li·ªáu (Highlight Document Snippets)**\n",
    "    * X√°c ƒë·ªãnh v√† l√†m n·ªïi b·∫≠t c√°c ph√¢n ƒëo·∫°n ch√≠nh x√°c t·ª´ c√°c t√†i li·ªáu ƒë∆∞·ª£c truy xu·∫•t ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi cu·ªëi c√πng.\n",
    "\n",
    "### C√°c c√¢n nh·∫Øc b·ªï sung\n",
    "\n",
    "* **H·∫°n ch·∫ø (Limitations):** Hi·ªáu su·∫•t c·ªßa h·ªá th·ªëng ph·ª• thu·ªôc v√†o ch·∫•t l∆∞·ª£ng c·ªßa embeddings v√† hi·ªáu qu·∫£ c·ªßa c∆° ch·∫ø ph√°t hi·ªán ·∫£o gi√°c.\n",
    "* **C·∫£i ti·∫øn ti·ªÅm nƒÉng (Potential Improvements):** Vi·ªác k·∫øt h·ª£p c√°c m√¥ h√¨nh ph·ª©c t·∫°p h∆°n ƒë·ªÉ ki·ªÉm tra m·ª©c ƒë·ªô li√™n quan v√† ph√°t hi·ªán ·∫£o gi√°c c√≥ th·ªÉ n√¢ng cao h∆°n n·ªØa ƒë·ªô tin c·∫≠y c·ªßa h·ªá th·ªëng.\n",
    "* **C√°c tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng c·ª• th·ªÉ (Specific Use Cases):** Ph∆∞∆°ng ph√°p n√†y ƒë·∫∑c bi·ªát h·ªØu √≠ch trong c√°c lƒ©nh v·ª±c m√† t√≠nh ch√≠nh x√°c v√† minh b·∫°ch c·ªßa s·ª± ki·ªán l√† t·ªëi quan tr·ªçng, ch·∫≥ng h·∫°n nh∆∞ nghi√™n c·ª©u ph√°p l√Ω ho·∫∑c h·ªçc thu·∫≠t.\n",
    "\n",
    "<img src=\"images/reliable_rag.svg\" alt=\"Reliable-RAG\" width=\"300\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "/tmp/ipykernel_687036/4271464747.py:15: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding_model = OllamaEmbeddings(model=embedding_model_name)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path='.env')\n",
    "\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "embedding_model_name='bge-m3:latest'\n",
    "llm_model_name='qwen2.5:7b'\n",
    "\n",
    "# set embedding\n",
    "embedding_model = OllamaEmbeddings(model=embedding_model_name)\n",
    "\n",
    "# Docs to index\n",
    "urls = [\n",
    "    \"https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?ref=dl-staging-website.ghost.io\",\n",
    "    \"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/?ref=dl-staging-website.ghost.io\",\n",
    "    \"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?ref=dl-staging-website.ghost.io\",\n",
    "    \"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-4-planning/?ref=dl-staging-website.ghost.io\",\n",
    "    \"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/?ref=dl-staging-website.ghost.io\"\n",
    "]\n",
    "\n",
    "# Load\n",
    "docs = [WebBaseLoader(url).load() for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?ref=dl-staging-website.ghost.io', 'title': 'Four AI Agent Strategies That Improve GPT-4 and GPT-3.5 Performance', 'description': 'I think AI agent workflows will drive massive AI progress this year ‚Äî perhaps even more than the next generation of foundation models. This is an important...', 'language': 'en'}, page_content='Four AI Agent Strategies That Improve GPT-4 and GPT-3.5 Performance‚ú® New course! Enroll in Long-Term Agentic Memory with LangGraphExplore CoursesAI NewsletterThe BatchAndrew\\'s LetterData PointsML ResearchBlog‚ú® AI Dev 25CommunityForumEventsAmbassadorsAmbassador SpotlightResourcesCompanyAboutCareersContactStart LearningWeekly IssuesAndrew\\'s LettersData PointsML ResearchBusinessScienceCultureHardwareAI CareersAboutSubscribeThe BatchLettersArticleAgentic Design Patterns Part 1 Four AI agent strategies that improve GPT-4 and GPT-3.5 performanceLettersTechnical InsightsPublishedMar 20, 2024Reading time2 min readShareDear friends,I think AI agent workflows will drive massive AI progress this year ‚Äî perhaps even more than the next generation of foundation models. This is an important trend, and I urge everyone who works in AI to pay attention to it.Today, we mostly use LLMs in zero-shot mode, prompting a model to generate final output token by token without revising its work. This is akin to asking someone to compose an essay from start to finish, typing straight through with no backspacing allowed, and expecting a high-quality result. Despite the difficulty, LLMs do amazingly well at this task!\\xa0With an agent workflow, however, we can ask the LLM to iterate over a document many times. For example, it might take a sequence of steps such as:Plan an outline.Decide what, if any, web searches are needed to gather more information.Write a first draft.Read over the first draft to spot unjustified arguments or extraneous information.Revise the draft taking into account any weaknesses spotted.And so on.This iterative process is critical for most human writers to write good text. With AI, such an iterative workflow yields much better results than writing in a single pass.\\xa0Devin‚Äôs splashy demo recently received a lot of social media buzz. My team has been closely following the evolution of AI that writes code. We analyzed results from a number of research teams, focusing on an algorithm‚Äôs ability to do well on the widely used HumanEval coding benchmark. You can see our findings in the diagram below.\\xa0GPT-3.5 (zero shot) was 48.1% correct. GPT-4 (zero shot) does better at 67.0%. However, the improvement from GPT-3.5 to GPT-4 is dwarfed by incorporating an iterative agent workflow. Indeed, wrapped in an agent loop, GPT-3.5 achieves up to 95.1%.\\xa0Open source agent tools and the academic literature on agents are proliferating, making this an exciting time but also a confusing one. To help put this work into perspective, I‚Äôd like to share a framework for categorizing design patterns for building agents. My team AI Fund is successfully using these patterns in many applications, and I hope you find them useful.Reflection: The LLM examines its own work to come up with ways to improve it.\\xa0Tool Use: The LLM is given tools such as web search, code execution, or any other function to help it gather information, take action, or process data.Planning: The LLM comes up with, and executes, a multistep plan to achieve a goal (for example, writing an outline for an essay, then doing online research, then writing a draft, and so on).Multi-agent collaboration: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.Next week, I‚Äôll elaborate on these design patterns and offer suggested readings for each.Keep learning!AndrewRead \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 3, Tool Use\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout\\n'),\n",
       " Document(metadata={'source': 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/?ref=dl-staging-website.ghost.io', 'title': 'Agentic Design Patterns Part 2: Reflection', 'description': 'Last week, I described four design patterns for AI agentic workflows that I believe will drive significant progress this year: Reflection, Tool use...', 'language': 'en'}, page_content='Agentic Design Patterns Part 2: Reflection‚ú® New course! Enroll in Long-Term Agentic Memory with LangGraphExplore CoursesAI NewsletterThe BatchAndrew\\'s LetterData PointsML ResearchBlog‚ú® AI Dev 25CommunityForumEventsAmbassadorsAmbassador SpotlightResourcesCompanyAboutCareersContactStart LearningWeekly IssuesAndrew\\'s LettersData PointsML ResearchBusinessScienceCultureHardwareAI CareersAboutSubscribeThe BatchLettersArticleAgentic Design Patterns Part 2, Reflection Large language models can become more effective agents by reflecting on their own behavior.LettersTechnical InsightsPublishedMar 27, 2024Reading time2 min readShareDear friends,Last week, I described four design patterns for AI agentic workflows that I believe will drive significant progress this year: Reflection, Tool Use, Planning and Multi-agent collaboration. Instead of having an LLM generate its final output directly, an agentic workflow prompts the LLM multiple times, giving it opportunities to build step by step to higher-quality output. In this letter, I\\'d like to discuss Reflection. For a design pattern that‚Äôs relatively quick to implement, I\\'ve seen it lead to surprising performance gains.\\xa0You may have had the experience of prompting ChatGPT/Claude/Gemini, receiving unsatisfactory output, delivering critical feedback to help the LLM improve its response, and then getting a better response. What if you automate the step of delivering critical feedback, so the model automatically criticizes its own output and improves its response? This is the crux of Reflection.\\xa0Take the task of asking an LLM to write code. We can prompt it to generate the desired code directly to carry out some task X. After that, we can prompt it to reflect on its own output, perhaps as follows:Here‚Äôs code intended for task X: [previously generated code]\\xa0 \\xa0\\xa0Check the code carefully for correctness, style, and efficiency, and give constructive criticism for how to improve it.Sometimes this causes the LLM to spot problems and come up with constructive suggestions. Next, we can prompt the LLM with context including (i) the previously generated code and the constructive feedback and (ii) ask it to use the feedback to rewrite the code. This can lead to a better response. Repeating the criticism/rewrite process might yield further improvements. This self-reflection process allows the LLM to spot gaps and improve its output on a variety of tasks including producing code, writing text, and answering questions.\\xa0And we can go beyond self-reflection by giving the LLM tools that help evaluate its output; for example, running its code through a few unit tests to check whether it generates correct results on test cases or searching the web to double-check text output. Then it can reflect on any errors it found and come up with ideas for improvement.Further, we can implement Reflection using a multi-agent framework. I\\'ve found it convenient to create two different agents, one prompted to generate good outputs and the other prompted to give constructive criticism of the first agent\\'s output. The resulting discussion between the two agents leads to improved responses.Reflection is a relatively basic type of agentic workflow, but I\\'ve been delighted by how much it improved my applications‚Äô results in a few cases. I hope you will try it in your own work. If you‚Äôre interested in learning more about reflection, I recommend these papers:‚ÄúSelf-Refine: Iterative Refinement with Self-Feedback,‚Äù Madaan et al. (2023)‚ÄúReflexion: Language Agents with Verbal Reinforcement Learning,‚Äù Shinn et al. (2023)‚ÄúCRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing,‚Äù Gou et al. (2024)I‚Äôll discuss the other agentic design patterns in future letters.Keep learning!Andrew\\xa0Read \"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 3, Tool Use\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout\\n'),\n",
       " Document(metadata={'source': 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?ref=dl-staging-website.ghost.io', 'title': 'Agentic Design Patterns Part 3: Tool Use', 'description': 'Tool use, in which an LLM is given functions it can request to call for gathering information, taking action, or manipulating data, is a key design...', 'language': 'en'}, page_content='Agentic Design Patterns Part 3: Tool Use‚ú® New course! Enroll in Long-Term Agentic Memory with LangGraphExplore CoursesAI NewsletterThe BatchAndrew\\'s LetterData PointsML ResearchBlog‚ú® AI Dev 25CommunityForumEventsAmbassadorsAmbassador SpotlightResourcesCompanyAboutCareersContactStart LearningWeekly IssuesAndrew\\'s LettersData PointsML ResearchBusinessScienceCultureHardwareAI CareersAboutSubscribeThe BatchLettersArticleAgentic Design Patterns Part 3, Tool Use How large language models can act as agents by taking advantage of external tools for search, code execution, productivity, ad infinitumLettersTechnical InsightsApril 03, 2024PublishedApr 3, 2024Reading time3 min readShareDear friends,Tool Use, in which an LLM is given functions it can request to call for gathering information, taking action, or manipulating data, is a key design pattern of\\xa0AI agentic workflows. You may be familiar with LLM-based systems that can perform a web search or execute code. Indeed, some large, consumer-facing LLMs already incorporate these features. But Tool Use goes well beyond these examples.\\xa0If you prompt an online LLM-based chat system, ‚ÄúWhat is the best coffee maker according to reviewers?‚Äù, it might decide to carry out a web search and download one or more web pages to gain context. Early on, LLM developers realized that relying only on a pre-trained transformer to generate output tokens is limiting, and that giving an LLM a tool for web search lets it do much more. With such a tool, an LLM is either fine-tuned or prompted (perhaps with few-shot prompting) to generate a special string like {tool: web-search, query: \"coffee maker reviews\"} to request calling a search engine. (The exact format of the string depends on the implementation.) A post-processing step then looks for strings like these, calls the web search function with the relevant parameters when it finds one, and passes the result back to the LLM as additional input context for further processing.\\xa0Similarly, if you ask, ‚ÄúIf I invest $100 at compound 7% interest for 12 years, what do I have at the end?‚Äù, rather than trying to generate the answer directly using a transformer network ‚Äî which is unlikely to result in the right answer ‚Äî the LLM might use a code execution tool to run a Python command to compute 100 * (1+0.07)**12 to get the right answer. The LLM might generate a string like this: {tool: python-interpreter, code: \"100 * (1+0.07)**12\"}.\\xa0But Tool Use in agentic workflows now goes much further. Developers are using functions to search different sources (web, Wikipedia, arXiv, etc.), to interface with productivity tools (send email, read/write calendar entries, etc.), generate or interpret images, and much more. We can prompt an LLM using context that gives detailed descriptions of many functions. These descriptions might include a text description of what the function does plus details of what arguments the function expects. And we‚Äôd expect the LLM to automatically choose the right function to call to do a job.\\xa0Further, systems are being built in which the LLM has access to hundreds of tools. In such settings, there might be too many functions at your disposal to put all of them into the LLM context, so you might use heuristics to pick the most relevant subset to include in the LLM context at the current step of processing. This technique, which is described in the Gorilla paper cited below, is reminiscent of how, if there is too much text to include as context, retrieval augmented generation (RAG) systems offer heuristics for picking a subset of the text to include.\\xa0Early in the history of LLMs, before widespread availability of large multimodal models (LMMs) \\xa0like LLaVa, GPT-4V, and Gemini, LLMs could not process images directly, so a lot of work on Tool Use was carried out by the computer vision community. At that time, the only way for an LLM-based system to manipulate an image was by calling a function to, say, carry out object recognition or some other function on it. Since then, practices for Tool Use have exploded. GPT-4‚Äôs function calling capability, released in the middle of last year, was a significant step toward a general-purpose implementation. Since then, more and more LLMs are being developed to be similarly facile with Tool Use.\\xa0If you‚Äôre interested in learning more about Tool Use, I recommend:\\xa0‚ÄúGorilla: Large Language Model Connected with Massive APIs,‚Äù Patil et al. (2023)‚ÄúMM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action,‚Äù Yang et al. (2023)‚ÄúEfficient Tool Use with Chain-of-Abstraction Reasoning,‚Äù Gao et al. (2024)\\xa0 \\xa0Both Tool Use and Reflection, which I described in last week‚Äôs\\xa0letter, are design patterns that I can get to work fairly reliably on my applications ‚Äî both are capabilities well worth learning about. In future letters, I‚Äôll describe the Planning and Multi-agent collaboration design patterns. They allow AI agents to do much more but are less mature, less predictable ‚Äî albeit very exciting ‚Äî technologies.\\xa0Keep learning!AndrewRead \"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout\\n'),\n",
       " Document(metadata={'source': 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-4-planning/?ref=dl-staging-website.ghost.io', 'title': 'Agentic Design Patterns Part 4: Planning', 'description': 'Planning is a key\\xa0agentic AI design pattern\\xa0in which we use a large language model (LLM) to autonomously decide on what sequence of steps to execute...', 'language': 'en'}, page_content='Agentic Design Patterns Part 4: Planning‚ú® New course! Enroll in Long-Term Agentic Memory with LangGraphExplore CoursesAI NewsletterThe BatchAndrew\\'s LetterData PointsML ResearchBlog‚ú® AI Dev 25CommunityForumEventsAmbassadorsAmbassador SpotlightResourcesCompanyAboutCareersContactStart LearningWeekly IssuesAndrew\\'s LettersData PointsML ResearchBusinessScienceCultureHardwareAI CareersAboutSubscribeThe BatchLettersArticleAgentic Design Patterns Part 4, Planning Large language models can drive powerful agents to execute complex tasks if you ask them to plan the steps before they act.LettersTechnical InsightsPublishedApr 10, 2024Reading time3 min readShareDear friends,Planning is a key\\xa0agentic AI design pattern\\xa0in which we use a large language model (LLM) to autonomously decide on what sequence of steps to execute to accomplish a larger task. For example, if we ask an agent to do online research on a given topic, we might use an LLM to break down the objective into smaller subtasks, such as researching specific subtopics, synthesizing findings, and compiling a report.\\xa0Many people had a ‚ÄúChatGPT moment‚Äù shortly after ChatGPT was released, when they played with it and were surprised that it significantly exceeded their expectation of what AI can do. If you have not yet had a similar ‚ÄúAI Agentic moment,‚Äù I hope you will soon. I had one several months ago, when I presented a live demo of a research agent I had implemented that had access to various online search tools.\\xa0I had tested this agent multiple times privately, during which it consistently used a web search tool to gather information and wrote up a summary. During the live demo, though, the web search API unexpectedly returned with a rate limiting error. I thought my demo was about to fail publicly, and I dreaded what was to come next. To my surprise, the agent pivoted deftly to a Wikipedia search tool ‚Äî which I had forgotten I‚Äôd given it ‚Äî and completed the task using Wikipedia instead of web search.\\xa0This was an AI Agentic moment of surprise for me. I think many people who haven‚Äôt experienced such a moment yet will do so in the coming months. It‚Äôs a beautiful thing when you see an agent autonomously decide to do things in ways that you had not anticipated, and succeed as a result!Many tasks can‚Äôt be done in a single step or with a single tool invocation, but an agent can decide what steps to take. For example, to simplify an example from the HuggingGPT paper (cited below), if you want an agent to consider a picture of a boy and draw a picture of a girl in the same pose, the task might be decomposed into two distinct steps: (i) detect the pose in the picture of the boy and (ii) render a picture of a girl in the detected pose. An LLM might be fine-tuned or prompted (with few-shot prompting) to specify a plan by outputting a string like\\xa0\"{tool: pose-detection, input: image.jpg, output: temp1 } {tool: pose-to-image, input: temp1, output: final.jpg}\".\\xa0This structured output, which specifies two steps to take, then triggers software to invoke a pose detection tool followed by a pose-to-image tool to complete the task. (This example is for illustrative purposes only; HuggingGPT uses a different format.)\\xa0Admittedly, many agentic workflows do not need planning. For example, you might have an agent reflect on, and improve, its output a fixed number of times. In this case, the sequence of steps the agent takes is fixed and deterministic. But for complex tasks in which you aren‚Äôt able to specify a decomposition of the task into a set of steps ahead of time, Planning allows the agent to decide dynamically what steps to take.\\xa0On one hand, Planning is a very powerful capability; on the other, it leads to less predictable results. In my experience, while I can get the agentic design patterns of\\xa0Reflection\\xa0and\\xa0Tool Use\\xa0to work reliably and improve my applications‚Äô performance, Planning is a less mature technology, and I find it hard to predict in advance what it will do. But the field continues to evolve rapidly, and I\\'m confident that Planning abilities will improve quickly.\\xa0If you‚Äôre interested in learning more about Planning with LLMs, I recommend:‚ÄúChain-of-Thought Prompting Elicits Reasoning in Large Language Models,‚Äù Wei et al. (2022)‚ÄúHuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face,‚Äù Shen et al. (2023)‚ÄúUnderstanding the planning of LLM agents: A survey,‚Äù by Huang et al. (2024)Keep learning!AndrewRead \"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 2: Reflection\"\\xa0Read \"Agentic Design Patterns Part 3: Tool Use\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout\\n'),\n",
       " Document(metadata={'source': 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/?ref=dl-staging-website.ghost.io', 'title': 'Agentic Design Patterns Part 5, Multi-Agent Collaboration', 'description': 'Multi-agent collaboration is the last of the four\\xa0key AI agentic design patterns\\xa0that I‚Äôve described in recent letters...', 'language': 'en'}, page_content='Agentic Design Patterns Part 5, Multi-Agent Collaboration‚ú® New course! Enroll in Long-Term Agentic Memory with LangGraphExplore CoursesAI NewsletterThe BatchAndrew\\'s LetterData PointsML ResearchBlog‚ú® AI Dev 25CommunityForumEventsAmbassadorsAmbassador SpotlightResourcesCompanyAboutCareersContactStart LearningWeekly IssuesAndrew\\'s LettersData PointsML ResearchBusinessScienceCultureHardwareAI CareersAboutSubscribeThe BatchLettersArticleAgentic Design Patterns Part 5, Multi-Agent Collaboration Prompting an LLM to play different roles for different parts of a complex task summons a team of AI agents that can do the job more effectively.LettersTechnical InsightsPublishedApr 17, 2024Reading time3 min readShareDear friends,Multi-agent collaboration is the last of the four\\xa0key AI agentic design patterns\\xa0that I‚Äôve described in recent letters. Given a complex task like writing software, a multi-agent approach would break down the task into subtasks to be executed by different roles ‚Äî such as a software engineer, product manager, designer, QA (quality assurance) engineer, and so on ‚Äî and have different agents accomplish different subtasks.Different agents might be built by prompting one LLM (or, if you prefer, multiple LLMs) to carry out different tasks. For example, to build a software engineer agent, we might prompt the LLM: ‚ÄúYou are an expert in writing clear, efficient code. Write code to perform the task . . ..‚Äù\\xa0It might seem counterintuitive that, although we are making multiple calls to the same LLM, we apply the programming abstraction of using multiple agents. I‚Äôd like to offer a few reasons:It works! Many teams are getting good results with this method, and there‚Äôs nothing like results! Further, ablation studies (for example, in the AutoGen paper cited below) show that multiple agents give superior performance to a single agent.\\xa0Even though some LLMs today can accept very long input contexts (for instance, Gemini 1.5 Pro accepts 1 million tokens), their ability to truly understand long, complex inputs is mixed. An agentic workflow in which the LLM is prompted to focus on one thing at a time can give better performance. By telling it when it should play software engineer, we can also specify what is important in that role‚Äôs subtask. For example, the prompt above emphasized clear, efficient code as opposed to, say, scalable and highly secure code. By decomposing the overall task into subtasks, we can optimize the subtasks better.Perhaps most important, the multi-agent design pattern gives us, as developers, a framework for breaking down complex tasks into subtasks. When writing code to run on a single CPU, we often break our program up into different processes or threads. This is a useful abstraction that lets us decompose a task, like implementing a web browser, into subtasks that are easier to code. I find thinking through multi-agent roles to be a useful abstraction as well.In many companies, managers routinely decide what roles to hire, and then how to split complex projects ‚Äî like writing a large piece of software or preparing a research report ‚Äî into smaller tasks to assign to employees with different specialties. Using multiple agents is analogous. Each agent implements its own workflow, has its own memory (itself a rapidly evolving area in agentic technology: how can an agent remember enough of its past interactions to perform better on upcoming ones?), and may ask other agents for help. Agents can also engage in Planning and Tool Use. This results in a cacophony of LLM calls and message passing between agents that can result in very complex workflows.\\xa0While managing people is hard, it\\'s a sufficiently familiar idea that it gives us a mental framework for how to \"hire\" and assign tasks to our AI agents. Fortunately, the damage from mismanaging an AI agent is much lower than that from mismanaging humans!\\xa0Emerging frameworks like AutoGen, Crew AI, and LangGraph, provide rich ways to build multi-agent solutions to problems. If you\\'re interested in playing with a fun multi-agent system, also check out ChatDev, an open source implementation of a set of agents that run a virtual software company. I encourage you to check out their\\xa0GitHub repo\\xa0and perhaps clone the repo and run the system yourself. While it may not always produce what you want, you might be amazed at how well it does.\\xa0Like the design pattern of\\xa0Planning, I find the output quality of multi-agent collaboration hard to predict, especially when allowing agents to interact freely and providing them with multiple tools. The more mature patterns of\\xa0Reflection\\xa0and\\xa0Tool Use\\xa0are more reliable. I hope you enjoy playing with these agentic design patterns and that they produce amazing results for you!\\xa0If you\\'re interested in learning more, I recommend:\\xa0‚ÄúCommunicative Agents for Software Development,‚Äù Qian et al. (2023) (the ChatDev paper)‚ÄúAutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation,‚Äù Wu et al. (2023)\\xa0‚ÄúMetaGPT: Meta Programming for a Multi-Agent Collaborative Framework,‚Äù Hong et al. (2023)Keep learning!AndrewRead \"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 2: Reflection\"\\xa0Read \"Agentic Design Patterns Part 3: Tool Use\"Read \"Agentic Design Patterns Part 4:\\xa0Planning\" ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout\\n')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "docs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=500, chunk_overlap=0)\n",
    "doc_splits = text_splitter.split_documents(docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to vector store\n",
    "vectorstore = Chroma.from_documents(\n",
    "  documents=doc_splits,\n",
    "  collection_name='rag',\n",
    "  embedding=embedding_model\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "  search_type=\"similarity\",\n",
    "  search_kwargs={'k': 4}, # number of documents to retrieve\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what are the differnt kind of agentic design patterns?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'description': 'Tool use, in which an LLM is given functions it can request to call for gathering information, taking action, or manipulating data, is a key design...', 'language': 'en', 'source': 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?ref=dl-staging-website.ghost.io', 'title': 'Agentic Design Patterns Part 3: Tool Use'}, page_content='(2023)‚ÄúMM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action,‚Äù Yang et al. (2023)‚ÄúEfficient Tool Use with Chain-of-Abstraction Reasoning,‚Äù Gao et al. (2024)\\xa0 \\xa0Both Tool Use and Reflection, which I described in last week‚Äôs\\xa0letter, are design patterns that I can get to work fairly reliably on my applications ‚Äî both are capabilities well worth learning about. In future letters, I‚Äôll describe the Planning and Multi-agent collaboration design patterns. They allow AI agents to do much more but are less mature, less predictable ‚Äî albeit very exciting ‚Äî technologies.\\xa0Keep learning!AndrewRead \"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout'),\n",
       " Document(metadata={'description': 'Planning is a key\\xa0agentic AI design pattern\\xa0in which we use a large language model (LLM) to autonomously decide on what sequence of steps to execute...', 'language': 'en', 'source': 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-4-planning/?ref=dl-staging-website.ghost.io', 'title': 'Agentic Design Patterns Part 4: Planning'}, page_content='(2023)‚ÄúUnderstanding the planning of LLM agents: A survey,‚Äù by Huang et al. (2024)Keep learning!AndrewRead \"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 2: Reflection\"\\xa0Read \"Agentic Design Patterns Part 3: Tool Use\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout'),\n",
       " Document(metadata={'description': 'I think AI agent workflows will drive massive AI progress this year ‚Äî perhaps even more than the next generation of foundation models. This is an important...', 'language': 'en', 'source': 'https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?ref=dl-staging-website.ghost.io', 'title': 'Four AI Agent Strategies That Improve GPT-4 and GPT-3.5 Performance'}, page_content='GPT-3.5 to GPT-4 is dwarfed by incorporating an iterative agent workflow. Indeed, wrapped in an agent loop, GPT-3.5 achieves up to 95.1%.\\xa0Open source agent tools and the academic literature on agents are proliferating, making this an exciting time but also a confusing one. To help put this work into perspective, I‚Äôd like to share a framework for categorizing design patterns for building agents. My team AI Fund is successfully using these patterns in many applications, and I hope you find them useful.Reflection: The LLM examines its own work to come up with ways to improve it.\\xa0Tool Use: The LLM is given tools such as web search, code execution, or any other function to help it gather information, take action, or process data.Planning: The LLM comes up with, and executes, a multistep plan to achieve a goal (for example, writing an outline for an essay, then doing online research, then writing a draft, and so on).Multi-agent collaboration: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.Next week, I‚Äôll elaborate on these design patterns and offer suggested readings for each.Keep learning!AndrewRead \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 3, Tool Use\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout'),\n",
       " Document(metadata={'description': 'Multi-agent collaboration is the last of the four\\xa0key AI agentic design patterns\\xa0that I‚Äôve described in recent letters...', 'language': 'en', 'source': 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/?ref=dl-staging-website.ghost.io', 'title': 'Agentic Design Patterns Part 5, Multi-Agent Collaboration'}, page_content='you\\'re interested in learning more, I recommend:\\xa0‚ÄúCommunicative Agents for Software Development,‚Äù Qian et al. (2023) (the ChatDev paper)‚ÄúAutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation,‚Äù Wu et al. (2023)\\xa0‚ÄúMetaGPT: Meta Programming for a Multi-Agent Collaborative Framework,‚Äù Hong et al. (2023)Keep learning!AndrewRead \"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 2: Reflection\"\\xa0Read \"Agentic Design Patterns Part 3: Tool Use\"Read \"Agentic Design Patterns Part 4:\\xa0Planning\" ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_docs = retriever.invoke(question)\n",
    "retriever_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Agentic Design Patterns Part 3: Tool Use\n",
      "\n",
      "Source: https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?ref=dl-staging-website.ghost.io\n",
      "\n",
      "Content: (2023)‚ÄúMM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action,‚Äù Yang et al. (2023)‚ÄúEfficient Tool Use with Chain-of-Abstraction Reasoning,‚Äù Gao et al. (2024)¬† ¬†Both Tool Use and Reflection, which I described in last week‚Äôs¬†letter, are design patterns that I can get to work fairly reliably on my applications ‚Äî both are capabilities well worth learning about. In future letters, I‚Äôll describe the Planning and Multi-agent collaboration design patterns. They allow AI agents to do much more but are less mature, less predictable ‚Äî albeit very exciting ‚Äî technologies.¬†Keep learning!AndrewRead \"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Title: {retriever_docs[0].metadata['title']}\\n\\nSource: {retriever_docs[0].metadata['source']}\\n\\nContent: {retriever_docs[0].page_content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check document relevancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "llm = ChatOllama(model=llm_model_name)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2023)‚ÄúMM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action,‚Äù Yang et al. (2023)‚ÄúEfficient Tool Use with Chain-of-Abstraction Reasoning,‚Äù Gao et al. (2024)¬† ¬†Both Tool Use and Reflection, which I described in last week‚Äôs¬†letter, are design patterns that I can get to work fairly reliably on my applications ‚Äî both are capabilities well worth learning about. In future letters, I‚Äôll describe the Planning and Multi-agent collaboration design patterns. They allow AI agents to do much more but are less mature, less predictable ‚Äî albeit very exciting ‚Äî technologies.¬†Keep learning!AndrewRead \"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout \n",
      " --------------------------------------------------\n",
      "binary_score='yes' \n",
      "\n",
      "(2023)‚ÄúUnderstanding the planning of LLM agents: A survey,‚Äù by Huang et al. (2024)Keep learning!AndrewRead \"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 2: Reflection\"¬†Read \"Agentic Design Patterns Part 3: Tool Use\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout \n",
      " --------------------------------------------------\n",
      "binary_score='yes' \n",
      "\n",
      "GPT-3.5 to GPT-4 is dwarfed by incorporating an iterative agent workflow. Indeed, wrapped in an agent loop, GPT-3.5 achieves up to 95.1%.¬†Open source agent tools and the academic literature on agents are proliferating, making this an exciting time but also a confusing one. To help put this work into perspective, I‚Äôd like to share a framework for categorizing design patterns for building agents. My team AI Fund is successfully using these patterns in many applications, and I hope you find them useful.Reflection: The LLM examines its own work to come up with ways to improve it.¬†Tool Use: The LLM is given tools such as web search, code execution, or any other function to help it gather information, take action, or process data.Planning: The LLM comes up with, and executes, a multistep plan to achieve a goal (for example, writing an outline for an essay, then doing online research, then writing a draft, and so on).Multi-agent collaboration: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.Next week, I‚Äôll elaborate on these design patterns and offer suggested readings for each.Keep learning!AndrewRead \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 3, Tool Use\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout \n",
      " --------------------------------------------------\n",
      "binary_score='yes' \n",
      "\n",
      "you're interested in learning more, I recommend:¬†‚ÄúCommunicative Agents for Software Development,‚Äù Qian et al. (2023) (the ChatDev paper)‚ÄúAutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation,‚Äù Wu et al. (2023)¬†‚ÄúMetaGPT: Meta Programming for a Multi-Agent Collaborative Framework,‚Äù Hong et al. (2023)Keep learning!AndrewRead \"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 2: Reflection\"¬†Read \"Agentic Design Patterns Part 3: Tool Use\"Read \"Agentic Design Patterns Part 4:¬†Planning\" ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout \n",
      " --------------------------------------------------\n",
      "binary_score='yes' \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter out the non-relevant docs\n",
    "docs_to_use = []\n",
    "for doc in retriever_docs:\n",
    "    print(doc.page_content, '\\n', '-'*50)\n",
    "    res = retrieval_grader.invoke({\"question\": question, \"document\": doc.page_content})\n",
    "    print(res,'\\n')\n",
    "    if res.binary_score == 'yes':\n",
    "        docs_to_use.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are four main kinds of agentic design patterns: Reflection, Tool Use, Planning, and Multi-agent collaboration. These patterns help AI agents improve their performance in various ways, from examining their own work to collaborate with other agents on complex tasks.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are an assistant for question-answering tasks. Answer the question based upon your knowledge. \n",
    "Use three-to-five sentences maximum and keep the answer concise.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved documents: \\n\\n <docs>{documents}</docs> \\n\\n User question: <question>{question}</question>\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=llm_model_name, temperature=0)\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\".join(f\"<doc{i+1}>:\\nTitle:{doc.metadata['title']}\\nSource:{doc.metadata['source']}\\nContent:{doc.page_content}\\n</doc{i+1}>\\n\" for i, doc in enumerate(docs))\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "generation = rag_chain.invoke({\"documents\":format_docs(docs_to_use), \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check halluciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "# Data model\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in 'generation' answer.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        ...,\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "# LLM with function call\n",
    "llm = ChatOllama(model=llm_model_name, temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n \n",
    "    Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Set of facts: \\n\\n <facts>{documents}</facts> \\n\\n LLM generation: <generation>{generation}</generation>\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "hallucination_grader = hallucination_prompt | structured_llm_grader\n",
    "\n",
    "response = hallucination_grader.invoke({\"documents\": format_docs(docs_to_use), \"generation\": generation})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hightlight used doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Data model\n",
    "class HighlightDocuments(BaseModel):\n",
    "    \"\"\"Return the specific part of a document used for answering the question.\"\"\"\n",
    "\n",
    "    id: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"List of id of docs used to answers the question\"\n",
    "    )\n",
    "\n",
    "    title: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"List of titles used to answers the question\"\n",
    "    )\n",
    "\n",
    "    source: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"List of sources used to answers the question\"\n",
    "    )\n",
    "\n",
    "    segment: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"List of direct segements from used documents that answers the question\"\n",
    "    )\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=llm_model_name, temperature=0)\n",
    "\n",
    "# parser\n",
    "parser = PydanticOutputParser(pydantic_object=HighlightDocuments)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are an advanced assistant for document search and retrieval. You are provided with the following:\n",
    "1. A question.\n",
    "2. A generated answer based on the question.\n",
    "3. A set of documents that were referenced in generating the answer.\n",
    "\n",
    "Your task is to identify and extract the exact inline segments from the provided documents that directly correspond to the content used to \n",
    "generate the given answer. The extracted segments must be verbatim snippets from the documents, ensuring a word-for-word match with the text \n",
    "in the provided documents.\n",
    "\n",
    "Ensure that:\n",
    "- (Important) Each segment is an exact match to a part of the document and is fully contained within the document text.\n",
    "- The relevance of each segment to the generated answer is clear and directly supports the answer provided.\n",
    "- (Important) If you didn't used the specific document don't mention it.\n",
    "\n",
    "Used documents: <docs>{documents}</docs> \\n\\n User question: <question>{question}</question> \\n\\n Generated answer: <answer>{generation}</answer>\n",
    "\n",
    "<format_instruction>\n",
    "{format_instructions}\n",
    "</format_instruction>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template= system,\n",
    "    input_variables=[\"documents\", \"question\", \"generation\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Chain\n",
    "doc_lookup = prompt | llm | parser\n",
    "\n",
    "# Run\n",
    "lookup_response = doc_lookup.invoke({\"documents\":format_docs(docs_to_use), \"question\": question, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ID: doc3\\n'\n",
      " 'Title: Four AI Agent Strategies That Improve GPT-4 and GPT-3.5 Performance\\n'\n",
      " 'Source: '\n",
      " 'https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?ref=dl-staging-website.ghost.io\\n'\n",
      " 'Text Segment: Reflection: The LLM examines its own work to come up with ways '\n",
      " 'to improve it.\\n')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "for id, title, source, segment in zip(lookup_response.id, lookup_response.title, lookup_response.source, lookup_response.segment):\n",
    "    pprint.pp(f\"ID: {id}\\nTitle: {title}\\nSource: {source}\\nText Segment: {segment}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
